{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "Model estimate Estimate sign of effect\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "None\n",
    "\n",
    "# Metadata\n",
    "\n",
    "- Key: 242_esg_metadata \n",
    "- Epic: Models\n",
    "- US: Estimate sign of effect\n",
    "- Task tag: #draft, #polymer, #sign-of-effect\n",
    "- Analytics reports: \n",
    "\n",
    "# Input\n",
    "\n",
    "## Table/file\n",
    "\n",
    "**Name**\n",
    "\n",
    "None\n",
    "\n",
    "**Github**\n",
    "\n",
    "- https://github.com/thomaspernet/esg_metadata/blob/master/02_data_analysis/01_model_train_evaluate/01_sign_of_effect/00_sign_of_effect_classification.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil, json\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-2'\n",
    "bucket = 'datalake-london'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'esg'\n",
    "table = 'meta_analysis_esg_cfp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)',\n",
    "                         'varchar(3)',\n",
    "                        'varchar(14)', 'varchar(11)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = True\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalog/temporary_local_data\")\n",
    "df_path = os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)\n",
    "    query = \"\"\"\n",
    "    WITH test as (\n",
    "  SELECT \n",
    "    *, concat(environmental,  social, governance) as filters\n",
    "  FROM {}.{} \n",
    "  WHERE \n",
    "    first_date_of_observations IS NOT NULL \n",
    "    and last_date_of_observations IS NOT NULL \n",
    "    and adjusted_model != 'TO_REMOVE' \n",
    ") \n",
    "SELECT \n",
    "  filters, to_remove, test.id, image, row_id_excel, row_id_google_spreadsheet,\n",
    "       table_refer, incremental_id, paper_name, publication_name,\n",
    "       rank, sjr, sjr_best_quartile, h_index, total_docs_2020,\n",
    "       total_docs_3years, total_refs, total_cites_3years,\n",
    "       citable_docs_3years, cites_doc_2years, country,\n",
    "       publication_year, publication_type, cnrs_ranking, peer_reviewed,\n",
    "       study_focused_on_social_environmental_behaviour, type_of_data,\n",
    "       study_focusing_on_developing_or_developed_countries, regions,\n",
    "       first_date_of_observations, last_date_of_observations,\n",
    "       windows, avg_windows, adjusted_model_name,\n",
    "       adjusted_model, dependent, adjusted_dependent, independent,\n",
    "       adjusted_independent, \n",
    "       CASE WHEN social = 'True' THEN 'YES' ELSE 'NO' END AS social,\n",
    "       CASE WHEN environmental = 'True' THEN 'YES' ELSE 'NO' END AS environmental,\n",
    "       CASE WHEN governance = 'True' THEN 'YES' ELSE 'NO' END AS governance,\n",
    "       CASE WHEN financial_crisis = True THEN 'YES' ELSE 'NO' END AS financial_crisis,\n",
    "       CASE WHEN kyoto = True THEN 'YES' ELSE 'NO' END AS kyoto,\n",
    "       lag,\n",
    "       interaction_term, quadratic_term, n, r2, beta,\n",
    "       sign_of_effect,target, significant, final_standard_error,\n",
    "       to_check_final, weight\n",
    "FROM \n",
    "  test \n",
    "  LEFT JOIN (\n",
    "    SELECT \n",
    "      id, \n",
    "      COUNT(*) as weight \n",
    "    FROM \n",
    "      test \n",
    "    GROUP BY \n",
    "      id\n",
    "  ) as c on test.id = c.id\n",
    "  WHERE filters != 'TrueTrueTrue' and filters != 'FalseFalseFalse' and sjr IS NOT NULL\n",
    "\n",
    "    \"\"\".format(db, table)\n",
    "    try:\n",
    "        df = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "    s3.download_file(\n",
    "        key = full_path_filename\n",
    "    )\n",
    "    shutil.move(\n",
    "        filename + '.csv',\n",
    "        os.path.join(path_local, filename + '.csv')\n",
    "    )\n",
    "    s3.remove_file(full_path_filename)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values().loc[lambda x: x> 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df['adjusted_model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## unbalanced ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = False\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "    data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename = [\n",
    "        {\n",
    "        'old':'working\\_capital\\_i',\n",
    "        'new':'\\\\text{working capital}_i'\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import latex.latex_beautify as lb\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge r-lmtest -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(\"sandwich\")\n",
    "library(\"lmtest\")\n",
    "#library(lfe)\n",
    "#library(lazyeval)\n",
    "#library(nnet)\n",
    "library('progress')\n",
    "path = \"../../../utils/latex/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get df_path\n",
    "df_final <- read_csv(df_path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "mutate(\n",
    "    sign_of_effect = relevel(sign_of_effect, ref='NEGATIVE'),\n",
    "    adjusted_model = relevel(adjusted_model, ref='OTHER'),\n",
    "    adjusted_dependent = relevel(adjusted_dependent, ref='OTHER'),\n",
    "      id = as.factor(id),\n",
    "    governance = relevel(as.factor(governance), ref = 'NO'),\n",
    "    social = relevel(as.factor(social), ref = 'NO'),\n",
    "    environmental =relevel(as.factor(environmental), ref = 'NO'),\n",
    "    financial_crisis =relevel(as.factor(financial_crisis), ref = 'NO'),\n",
    "    kyoto =relevel(as.factor(kyoto), ref = 'NO'),\n",
    "    target =relevel(as.factor(target), ref = 'NOT_SIGNIFICANT'),\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "glimpse(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "transpose(df_final %>% \n",
    "    select_if(function(x) any(is.na(x))) %>% \n",
    "    summarise_each(funs(sum(is.na(.)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "GLM does not clustered the standard error so, we compute it by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "se_robust <- function(x)\n",
    "  coeftest(x, vcov. = sandwich::sandwich\n",
    "          )[, 2]\n",
    "se_robust_clustered <- function(x)\n",
    "  coeftest(x,\n",
    "         vcov. = vcovCL(t_2, cluster = df_final %>% filter(adjusted_model != 'TO_REMOVE') %>% select(id), type = \"HC0\")\n",
    "        )[, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "## Table 1:Probit\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Write your equation}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- robust standard error\n",
    "- Cannot compute clustered standard error if we add features without variation among the cluster (i.e `n`, or journal information)\n",
    "\n",
    "TO estimate a probit, use `probit` link function.  For logistic regression, use `binomial`\n",
    "\n",
    "- Reason Probit instead of Logit\n",
    "    - [What is the Difference Between Logit and Probit Models?](https://tutorials.methodsconsultants.com/posts/what-is-the-difference-between-logit-and-probit-models/)\n",
    "\n",
    "Logit and probit differ in how they define $f(∗)$. The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define $f(∗)$.\n",
    "\n",
    "Probit models can be generalized to account for non-constant error variances in more advanced econometric settings (known as heteroskedastic probit models)\n",
    "\n",
    "**Comparison group**\n",
    "\n",
    "- Always `OTHER`\n",
    "- Target: `SIGNIFICANT`\n",
    "\n",
    "**How to read**\n",
    "\n",
    "- Categorical:\n",
    "    - Keeping all other variables constant, if the analysis uses FIXED EFFECT model, there are 2.71 times more likely to stay in the NEGATIVE sign category as compared to the OTHER model category. The coefficient, however, is not significant. (Col 1)\n",
    "- Continuous:\n",
    "    - Keeping all other variables constant, if the SJR score increases one unit, there is 1.003 times more likely to stay in the POSITIVE sign category as compared to the OTHER model category y (the risk or odds is .2% higher). The coefficient is significant.\n",
    "    \n",
    "Here, OTHER means insignificant\n",
    "\n",
    "Currently, issue with:\n",
    "\n",
    "- governance \n",
    "- full inclusion dummy -> probably collinearity need to check\n",
    "\n",
    "Test with Kyoto, financial crisis & region\n",
    "\n",
    "- CASE WHEN first_date_of_observations >= 1997 THEN TRUE ELSE FALSE END AS kyoto,\n",
    "- CASE WHEN first_date_of_observations >= 2009 THEN TRUE ELSE FALSE END AS financial_crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "t_0 <- glm(target ~ adjusted_model\n",
    "                + environmental \n",
    "                + kyoto \n",
    "                + financial_crisis+\n",
    "           +sjr,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_0.rrr <- exp(coef(t_0))\n",
    "t_1 <- glm(target ~ adjusted_model\n",
    "                + social \n",
    "                + kyoto \n",
    "                + financial_crisis+\n",
    "           sjr,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_1.rrr <- exp(coef(t_1))\n",
    "t_2 <- glm(target ~ adjusted_model\n",
    "                + governance \n",
    "                + kyoto \n",
    "                + financial_crisis+\n",
    "           sjr,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_2.rrr <- exp(coef(t_2))\n",
    "\n",
    "list_final = list(t_0, t_1, t_2)\n",
    "list_final.rrr = list(t_0.rrr,t_1.rrr ,t_2.rrr)\n",
    "stargazer(list_final, type = \"text\", \n",
    "  se = lapply(list_final,\n",
    "              se_robust),\n",
    "          coef=list_final.rrr,\n",
    "          omit = \"id\", style = \"qje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import make_toc\n",
    "import create_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "name_json = 'parameters_ETL_esg_metadata.json'\n",
    "path_json = os.path.join(str(Path(path).parent.parent), 'utils',name_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report.create_report(extension = \"html\", keep_code = True, notebookname = \"00_sign_of_effect_classification.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Update TOC in Github\n",
    "for p in [parent_path,\n",
    "          str(Path(path).parent),\n",
    "          #os.path.join(str(Path(path).parent), \"00_download_data_from\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"00_statistical_exploration\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"01_model_estimation\"),\n",
    "         ]:\n",
    "    try:\n",
    "        os.remove(os.path.join(p, 'README.md'))\n",
    "    except:\n",
    "        pass\n",
    "    path_parameter = os.path.join(parent_path,'utils', name_json)\n",
    "    md_lines =  make_toc.create_index(cwd = p, path_parameter = path_parameter)\n",
    "    md_out_fn = os.path.join(p,'README.md')\n",
    "    \n",
    "    if p == parent_path:\n",
    "    \n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = True, path_parameter = path_parameter)\n",
    "    else:\n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
