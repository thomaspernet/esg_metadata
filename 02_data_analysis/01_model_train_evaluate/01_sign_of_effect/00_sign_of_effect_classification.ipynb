{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "Model estimate Estimate sign of effect\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "None\n",
    "\n",
    "# Metadata\n",
    "\n",
    "- Key: 242_esg_metadata \n",
    "- Epic: Models\n",
    "- US: Estimate sign of effect\n",
    "- Task tag: #draft, #polymer, #sign-of-effect\n",
    "- Analytics reports: \n",
    "\n",
    "# Input\n",
    "\n",
    "## Table/file\n",
    "\n",
    "**Name**\n",
    "\n",
    "None\n",
    "\n",
    "**Github**\n",
    "\n",
    "- https://github.com/thomaspernet/esg_metadata/blob/master/02_data_analysis/01_model_train_evaluate/01_sign_of_effect/00_sign_of_effect_classification.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil, json\n",
    "import sys\n",
    "import janitor\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-2'\n",
    "bucket = 'datalake-london'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'esg'\n",
    "table = 'meta_analysis_esg_cfp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)',\n",
    "                         'varchar(3)',\n",
    "                        'varchar(14)', 'varchar(11)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = True\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalog/temporary_local_data\")\n",
    "df_path = os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)\n",
    "    query = \"\"\"\n",
    "    WITH test as (\n",
    "  SELECT \n",
    "    *, concat(environmental,  social, governance) as filters\n",
    "  FROM {}.{} \n",
    "  WHERE \n",
    "    first_date_of_observations IS NOT NULL \n",
    "    and last_date_of_observations IS NOT NULL \n",
    "    and adjusted_model != 'TO_REMOVE' \n",
    ") \n",
    "SELECT \n",
    "  filters, to_remove, test.id, image, row_id_excel, row_id_google_spreadsheet,\n",
    "       table_refer, incremental_id, paper_name, publication_name,\n",
    "       rank, sjr, sjr_best_quartile, h_index, total_docs_2020,\n",
    "       total_docs_3years, total_refs, total_cites_3years,\n",
    "       citable_docs_3years, cites_doc_2years, country,\n",
    "       publication_year, publication_type, cnrs_ranking, peer_reviewed,\n",
    "       study_focused_on_social_environmental_behaviour, type_of_data,\n",
    "       first_date_of_observations, last_date_of_observations,\n",
    "       windows, avg_windows, adjusted_model_name,\n",
    "       adjusted_model, dependent, adjusted_dependent, independent,\n",
    "       adjusted_independent, \n",
    "       CASE WHEN social = 'True' THEN 'YES' ELSE 'NO' END AS social,\n",
    "       CASE WHEN environmental = 'True' THEN 'YES' ELSE 'NO' END AS environmental,\n",
    "       CASE WHEN governance = 'True' THEN 'YES' ELSE 'NO' END AS governance,\n",
    "       CASE WHEN financial_crisis = True THEN 'YES' ELSE 'NO' END AS financial_crisis,\n",
    "       CASE WHEN kyoto = True THEN 'YES' ELSE 'NO' END AS kyoto,\n",
    "       CASE WHEN regions = 'ARAB WORLD' THEN 'WORLDWIDE' ELSE regions END AS regions,\n",
    "       CASE WHEN study_focusing_on_developing_or_developed_countries = 'Europe' THEN 'Worldwide' ELSE study_focusing_on_developing_or_developed_countries END AS study_focusing_on_developing_or_developed_countries,\n",
    "       lag,\n",
    "       interaction_term, quadratic_term, n, r2, beta,\n",
    "       sign_of_effect,target, significant, final_standard_error,\n",
    "       to_check_final, weight\n",
    "FROM \n",
    "  test \n",
    "  LEFT JOIN (\n",
    "    SELECT \n",
    "      id, \n",
    "      COUNT(*) as weight \n",
    "    FROM \n",
    "      test \n",
    "    GROUP BY \n",
    "      id\n",
    "  ) as c on test.id = c.id\n",
    "  WHERE filters != 'TrueTrueTrue' and filters != 'FalseFalseFalse' and sjr IS NOT NULL\n",
    "\n",
    "    \"\"\".format(db, table)\n",
    "    try:\n",
    "        df = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "    s3.download_file(\n",
    "        key = full_path_filename\n",
    "    )\n",
    "    shutil.move(\n",
    "        filename + '.csv',\n",
    "        os.path.join(path_local, filename + '.csv')\n",
    "    )\n",
    "    s3.remove_file(full_path_filename)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values().loc[lambda x: x> 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df['adjusted_model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## unbalanced ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = False\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "    data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename = [\n",
    "        {\n",
    "        'old':'working\\_capital\\_i',\n",
    "        'new':'\\\\text{working capital}_i'\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import latex.latex_beautify as lb\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge r-lmtest -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(\"sandwich\")\n",
    "library(\"lmtest\")\n",
    "#library(lfe)\n",
    "#library(lazyeval)\n",
    "#library(nnet)\n",
    "library('progress')\n",
    "path = \"../../../utils/latex/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get df_path\n",
    "df_final <- read_csv(df_path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "mutate(\n",
    "    sign_of_effect = relevel(sign_of_effect, ref='NEGATIVE'),\n",
    "    adjusted_model = relevel(adjusted_model, ref='OTHER'),\n",
    "    adjusted_dependent = relevel(adjusted_dependent, ref='OTHER'),\n",
    "      id = as.factor(id),\n",
    "    governance = relevel(as.factor(governance), ref = 'NO'),\n",
    "    social = relevel(as.factor(social), ref = 'NO'),\n",
    "    environmental =relevel(as.factor(environmental), ref = 'NO'),\n",
    "    financial_crisis =relevel(as.factor(financial_crisis), ref = 'NO'),\n",
    "    kyoto =relevel(as.factor(kyoto), ref = 'NO'),\n",
    "    target =relevel(as.factor(target), ref = 'NOT_SIGNIFICANT'),\n",
    "    study_focusing_on_developing_or_developed_countries =relevel(\n",
    "        as.factor(study_focusing_on_developing_or_developed_countries), ref = 'Worldwide'),\n",
    "    regions =relevel(as.factor(regions), ref = 'WORLDWIDE'),\n",
    "    cnrs_ranking =relevel(as.factor(cnrs_ranking), ref = '0'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "glimpse(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "transpose(df_final %>% \n",
    "    select_if(function(x) any(is.na(x))) %>% \n",
    "    summarise_each(funs(sum(is.na(.)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "GLM does not clustered the standard error so, we compute it by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "se_robust <- function(x)\n",
    "  coeftest(x, vcov. = sandwich::sandwich\n",
    "          )[, 2]\n",
    "se_robust_clustered <- function(x)\n",
    "  coeftest(x,\n",
    "         vcov. = vcovCL(t_2, cluster = df_final %>% filter(adjusted_model != 'TO_REMOVE') %>% select(id), type = \"HC0\")\n",
    "        )[, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "# Table 1: Baseline\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Write your equation}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- robust standard error\n",
    "- Cannot compute clustered standard error if we add features without variation among the cluster (i.e `n`, or journal information)\n",
    "\n",
    "TO estimate a probit, use `probit` link function.  For logistic regression, use `binomial`\n",
    "\n",
    "- Reason Probit instead of Logit\n",
    "    - [What is the Difference Between Logit and Probit Models?](https://tutorials.methodsconsultants.com/posts/what-is-the-difference-between-logit-and-probit-models/)\n",
    "\n",
    "Logit and probit differ in how they define $f(∗)$. The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define $f(∗)$.\n",
    "\n",
    "Probit models can be generalized to account for non-constant error variances in more advanced econometric settings (known as heteroskedastic probit models)\n",
    "\n",
    "**Comparison group**\n",
    "\n",
    "- Always `OTHER`\n",
    "- Target: `SIGNIFICANT`\n",
    "\n",
    "**How to read**\n",
    "\n",
    "- Categorical:\n",
    "    - Keeping all other variables constant, if the analysis uses FIXED EFFECT model, there are 2.71 times more likely to stay in the NEGATIVE sign category as compared to the OTHER model category. The coefficient, however, is not significant. (Col 1)\n",
    "- Continuous:\n",
    "    - Keeping all other variables constant, if the SJR score increases one unit, there is 1.003 times more likely to stay in the POSITIVE sign category as compared to the OTHER model category y (the risk or odds is .2% higher). The coefficient is significant.\n",
    "    \n",
    "Here, OTHER means insignificant\n",
    "\n",
    "Currently, issue with:\n",
    "\n",
    "- governance \n",
    "- full inclusion dummy -> probably collinearity need to check\n",
    "\n",
    "Test with Kyoto, financial crisis & region\n",
    "\n",
    "- CASE WHEN first_date_of_observations >= 1997 THEN TRUE ELSE FALSE END AS kyoto,\n",
    "- CASE WHEN first_date_of_observations >= 2009 THEN TRUE ELSE FALSE END AS financial_crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pd.concat(\n",
    "        [\n",
    "            (df.groupby(\"environmental\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'environment'}),\n",
    "            (df.groupby(\"social\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'social'}),\n",
    "            (df.groupby(\"governance\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'governance'}),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    .T\n",
    "    .reset_index()\n",
    "    .rename(columns = {'environmental':'is_dummy', 'level_0':'origin'})\n",
    "    .set_index(['origin','is_dummy'])\n",
    "    .assign(pct_significant = lambda x: x[('SIGNIFICANT')]/x.sum(axis= 1))\n",
    "    #\n",
    "    #\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('adjusted_model')\n",
    "    .agg(\n",
    "    {\n",
    "        'target':'value_counts'\n",
    "    })\n",
    "    .unstack(-1)\n",
    "    .assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pd.concat(\n",
    "        [\n",
    "            (df.groupby(\"kyoto\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'kyoto'}),\n",
    "            (df.groupby(\"financial_crisis\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'financial_crisis'}),\n",
    "            #(df.groupby(\"governance\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'governance'}),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    .T\n",
    "    .reset_index()\n",
    "    .rename(columns = {'kyoto':'is_dummy', 'level_0':'origin'})\n",
    "    .set_index(['origin','is_dummy'])\n",
    "    .assign(pct_significant = lambda x: x[('SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "t_0 <- glm(target ~ environmental,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_0.rrr <- exp(coef(t_0))\n",
    "t_1 <- glm(target ~social,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_1.rrr <- exp(coef(t_1))\n",
    "t_2 <- glm(target ~ governance ,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_2.rrr <- exp(coef(t_2))\n",
    "\n",
    "### add model\n",
    "t_3 <- glm(target ~ environmental+\n",
    "           adjusted_model  ,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_3.rrr <- exp(coef(t_3))\n",
    "t_4 <- glm(target ~ social+\n",
    "           adjusted_model,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_4.rrr <- exp(coef(t_4))\n",
    "t_5 <- glm(target ~ governance\n",
    "           +adjusted_model,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_5.rrr <- exp(coef(t_5))\n",
    "\n",
    "### add kyoto and financial crisis\n",
    "t_6 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "                + kyoto \n",
    "                + financial_crisis,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_6.rrr <- exp(coef(t_6))\n",
    "t_7 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "                + kyoto \n",
    "                + financial_crisis,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_7.rrr <- exp(coef(t_7))\n",
    "t_8 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "                + kyoto \n",
    "                + financial_crisis,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_8.rrr <- exp(coef(t_8))\n",
    "\n",
    "\n",
    "list_final = list(t_0, t_1, t_2, t_3, t_4, t_5, t_6, t_7, t_8)\n",
    "list_final.rrr = list(t_0.rrr,t_1.rrr ,t_2.rrr,t_3.rrr,t_4.rrr,t_5.rrr,t_6.rrr,t_7.rrr,t_8.rrr)\n",
    "stargazer(list_final, type = \"text\", \n",
    "  se = lapply(list_final,\n",
    "              se_robust),\n",
    "          coef=list_final.rrr,\n",
    "          omit = \"id\", style = \"qje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "# Table 2: Paper control\n",
    "\n",
    "- Add the following control:\n",
    "    - publication_year\n",
    "    - first_date_of_observations\n",
    "    - last_date_of_observations\n",
    "    - windows\n",
    "    - avg_windows\n",
    "    - lag\n",
    "    - interaction_term\n",
    "    - quadratic_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('target')\n",
    "    .agg(\n",
    "    {\n",
    "        'windows':'describe'\n",
    "    })\n",
    "    #.unstack(-1)\n",
    "    #.assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "t_0 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + publication_year\n",
    "           + first_date_of_observations\n",
    "           + last_date_of_observations\n",
    "           ,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_0.rrr <- exp(coef(t_0))\n",
    "t_1 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + publication_year\n",
    "           + first_date_of_observations\n",
    "           + last_date_of_observations,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_1.rrr <- exp(coef(t_1))\n",
    "t_2 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "            + kyoto \n",
    "            + financial_crisis\n",
    "           + publication_year\n",
    "           + first_date_of_observations\n",
    "           + last_date_of_observations,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_2.rrr <- exp(coef(t_2))\n",
    "\n",
    "### window \n",
    "t_3 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + publication_year\n",
    "           + windows,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_3.rrr <- exp(coef(t_3))\n",
    "t_4 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + publication_year\n",
    "           + windows,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_4.rrr <- exp(coef(t_4))\n",
    "t_5 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + publication_year\n",
    "           + windows,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_5.rrr <- exp(coef(t_5))\n",
    "\n",
    "list_final = list(t_0, t_1, t_2,t_3, t_4, t_5)\n",
    "list_final.rrr = list(t_0.rrr,t_1.rrr ,t_2.rrr,t_3.rrr,t_4.rrr ,t_5.rrr)\n",
    "stargazer(list_final, type = \"text\", \n",
    "  se = lapply(list_final,\n",
    "              se_robust),\n",
    "          coef=list_final.rrr,\n",
    "          omit = \"id\", style = \"qje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "- lag\n",
    "- interaction_term\n",
    "- quadratic_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pd.concat(\n",
    "        [\n",
    "            (df.groupby(\"lag\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'lag'}),\n",
    "            (df.groupby(\"interaction_term\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'interaction_term'}),\n",
    "            (df.groupby(\"quadratic_term\").agg({\"target\": \"value_counts\"}).unstack(0)).rename(columns = {'target':'quadratic_term'}),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    .T\n",
    "    .reset_index()\n",
    "    .rename(columns = {'lag':'is_dummy', 'level_0':'origin'})\n",
    "    .set_index(['origin','is_dummy'])\n",
    "    .assign(pct_significant = lambda x: x[('SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "### lag\n",
    "t_0 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + lag\n",
    "           ,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_0.rrr <- exp(coef(t_0))\n",
    "t_1 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + lag,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_1.rrr <- exp(coef(t_1))\n",
    "t_2 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "            + kyoto \n",
    "            + financial_crisis\n",
    "           + lag,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_2.rrr <- exp(coef(t_2))\n",
    "\n",
    "### interaction_term \n",
    "t_3 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + interaction_term,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_3.rrr <- exp(coef(t_3))\n",
    "t_4 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + interaction_term,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_4.rrr <- exp(coef(t_4))\n",
    "t_5 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + interaction_term,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_5.rrr <- exp(coef(t_5))\n",
    "\n",
    "### quadratic_term\n",
    "t_6 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + quadratic_term,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_6.rrr <- exp(coef(t_6))\n",
    "t_7 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + quadratic_term,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_7.rrr <- exp(coef(t_7))\n",
    "t_8 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + quadratic_term,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_8.rrr <- exp(coef(t_8))\n",
    "\n",
    "list_final = list(t_0, t_1, t_2,t_3, t_4, t_5, t_6,t_7, t_8)\n",
    "list_final.rrr = list(t_0.rrr,t_1.rrr ,t_2.rrr,t_3.rrr,t_4.rrr ,t_5.rrr,t_6.rrr,t_7.rrr ,t_8.rrr)\n",
    "stargazer(list_final, type = \"text\", \n",
    "  se = lapply(list_final,\n",
    "              se_robust),\n",
    "          coef=list_final.rrr,\n",
    "          omit = \"id\", style = \"qje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "# Table 3: Region\n",
    "\n",
    "- regions\n",
    "- study_focusing_on_developing_or_developed_countries\n",
    "\n",
    "Comparison group: \"WORLDWIDE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('regions')\n",
    "    .agg(\n",
    "    {\n",
    "        'target':'value_counts'\n",
    "    })\n",
    "    .unstack(-1)\n",
    "    .assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('study_focusing_on_developing_or_developed_countries')\n",
    "    .agg(\n",
    "    {\n",
    "        'target':'value_counts'\n",
    "    })\n",
    "    .unstack(-1)\n",
    "    .assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "### regions\n",
    "t_0 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + regions\n",
    "           ,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_0.rrr <- exp(coef(t_0))\n",
    "t_1 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + regions,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_1.rrr <- exp(coef(t_1))\n",
    "t_2 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "            + kyoto \n",
    "            + financial_crisis\n",
    "           + regions,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_2.rrr <- exp(coef(t_2))\n",
    "\n",
    "### study_focusing_on_developing_or_developed_countries \n",
    "t_3 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + study_focusing_on_developing_or_developed_countries,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_3.rrr <- exp(coef(t_3))\n",
    "t_4 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + study_focusing_on_developing_or_developed_countries,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_4.rrr <- exp(coef(t_4))\n",
    "t_5 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + study_focusing_on_developing_or_developed_countries,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_5.rrr <- exp(coef(t_5))\n",
    "\n",
    "\n",
    "list_final = list(t_0, t_1, t_2,t_3, t_4, t_5)\n",
    "list_final.rrr = list(t_0.rrr,t_1.rrr ,t_2.rrr,t_3.rrr,t_4.rrr ,t_5.rrr)\n",
    "stargazer(list_final, type = \"text\", \n",
    "  se = lapply(list_final,\n",
    "              se_robust),\n",
    "          coef=list_final.rrr,\n",
    "          omit = \"id\", style = \"qje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "# Table 4: Journal\n",
    "\n",
    "- sjr \n",
    "- sjr_best_quartile: Q1\n",
    "- cnrs_ranking: 0\n",
    "- h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('target')\n",
    "    .agg(\n",
    "    {\n",
    "        'sjr':'describe'\n",
    "    })\n",
    "    #.unstack(-1)\n",
    "    #.assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('sjr_best_quartile')\n",
    "    .agg(\n",
    "    {\n",
    "        'target':'value_counts'\n",
    "    })\n",
    "    .unstack(-1)\n",
    "    .assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('cnrs_ranking')\n",
    "    .agg(\n",
    "    {\n",
    "        'target':'value_counts'\n",
    "    })\n",
    "    .unstack(-1)\n",
    "    .assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('target')\n",
    "    .agg(\n",
    "    {\n",
    "        'h_index':'describe'\n",
    "    })\n",
    "    #.unstack(-1)\n",
    "    #.assign(pct_significant = lambda x: x[('target','SIGNIFICANT')]/x.sum(axis= 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "### sjr\n",
    "t_0 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + sjr\n",
    "           ,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_0.rrr <- exp(coef(t_0))\n",
    "t_1 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "                + kyoto \n",
    "                + financial_crisis\n",
    "           + sjr,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_1.rrr <- exp(coef(t_1))\n",
    "t_2 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "            + kyoto \n",
    "            + financial_crisis\n",
    "           + sjr,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_2.rrr <- exp(coef(t_2))\n",
    "\n",
    "### sjr_best_quartile \n",
    "t_3 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + sjr_best_quartile ,\n",
    "           data = df_final %>% filter(sjr_best_quartile != 'Q3'),\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_3.rrr <- exp(coef(t_3))\n",
    "t_4 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + sjr_best_quartile,\n",
    "           data = df_final %>% filter(sjr_best_quartile != 'Q3'), binomial(link = \"probit\"))\n",
    "t_4.rrr <- exp(coef(t_4))\n",
    "t_5 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + sjr_best_quartile,\n",
    "           data = df_final %>% filter(sjr_best_quartile != 'Q3'), binomial(link = \"probit\"))\n",
    "t_5.rrr <- exp(coef(t_5))\n",
    "\n",
    "### cnrs_ranking\n",
    "t_6 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + cnrs_ranking,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_6.rrr <- exp(coef(t_6))\n",
    "t_7 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + cnrs_ranking,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_7.rrr <- exp(coef(t_7))\n",
    "t_8 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + cnrs_ranking,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_8.rrr <- exp(coef(t_8))\n",
    "\n",
    "### h_index\n",
    "t_9 <- glm(target ~ environmental+\n",
    "           adjusted_model  \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + h_index,\n",
    "           data = df_final ,\n",
    "           binomial(link = \"probit\")\n",
    "          )\n",
    "t_9.rrr <- exp(coef(t_9))\n",
    "t_10 <- glm(target ~ social+\n",
    "           adjusted_model    \n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + h_index,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_10.rrr <- exp(coef(t_10))\n",
    "t_11 <- glm(target ~ governance\n",
    "           +adjusted_model\n",
    "           + kyoto \n",
    "           + financial_crisis\n",
    "           + h_index,\n",
    "           data = df_final , binomial(link = \"probit\"))\n",
    "t_11.rrr <- exp(coef(t_11))\n",
    "\n",
    "list_final = list(t_0, t_1, t_2,t_3, t_4, t_5, t_6,t_7, t_8, t_9,t_10, t_11)\n",
    "list_final.rrr = list(t_0.rrr,t_1.rrr ,t_2.rrr,t_3.rrr,t_4.rrr ,t_5.rrr,t_6.rrr,t_7.rrr ,t_8.rrr,t_9.rrr,t_10.rrr ,t_11.rrr)\n",
    "stargazer(list_final, type = \"text\", \n",
    "  se = lapply(list_final,\n",
    "              se_robust),\n",
    "          coef=list_final.rrr,\n",
    "          omit = \"id\", style = \"qje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import make_toc\n",
    "import create_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "name_json = 'parameters_ETL_esg_metadata.json'\n",
    "path_json = os.path.join(str(Path(path).parent.parent), 'utils',name_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report.create_report(extension = \"html\", keep_code = True, notebookname = \"00_sign_of_effect_classification.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Update TOC in Github\n",
    "for p in [parent_path,\n",
    "          str(Path(path).parent),\n",
    "          #os.path.join(str(Path(path).parent), \"00_download_data_from\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"00_statistical_exploration\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"01_model_estimation\"),\n",
    "         ]:\n",
    "    try:\n",
    "        os.remove(os.path.join(p, 'README.md'))\n",
    "    except:\n",
    "        pass\n",
    "    path_parameter = os.path.join(parent_path,'utils', name_json)\n",
    "    md_lines =  make_toc.create_index(cwd = p, path_parameter = path_parameter)\n",
    "    md_out_fn = os.path.join(p,'README.md')\n",
    "    \n",
    "    if p == parent_path:\n",
    "    \n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = True, path_parameter = path_parameter)\n",
    "    else:\n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
