# Data Analysis

In our workflow, the analytical part is divided into 3 parts:

1. Analysis:  folder `00_analysis` 
2. Training and evaluating: folder `01_model_train_evaluate` 
3. Training and deployment: folder `02_model_train_deploy`
4. Prediction:  folder `03_model_prediction` 



Folder `00_analysis`  and `01_model_train_evaluate`  are composed by two child folders:

- `00_XX_POC`:
  - Allow to carry out test on the dataset
- `Reports` 
  - provide HTML report to ease the reading



The root folder should contains only the notebook that will go to the deployment stage or are used for the final step. Notebooks created for test purposed should be located in the child folder `00_XX_POC` . 



## Analysis

The analytical part is done in folder `00_analysis_XX`. In this folder, the data scientist can make as much statistical as possible. The main purposes behind this folder is to tell a story with the data. 



The analytical part should also be an opportunity for the data scientist to better understand the dataset, the rules and underlying pattern. 



Any testing should be made in a subfolder, named incrementaly, starting with `00_analysis_XX_POC` . 



All notebooks should be exported in HTML format in the `Reports` subfolder. 



## Model training and evaluating

The model training is done in the folder `01_model_train_evaluate`. Any testing should be made in a subfolder, named incrementaly, starting with `00_model_XX_POC` .  All models hyperparameters tunning or other relevant tests should be saved in json in the subfolder `final_results` . It helps to replicate the results with the given parameters.

All notebooks should be exported in HTML format in the `Reports` subfolder. 

The folder contains a child, `Docker`, with the Dockerfile if needed. 

## Model train and deploy

In the previous step, the model has been preprocessed, trained and evaluated. Now, the model is ready to be deployed. The notebook to deploy the pipeline (Load, preprocessed, train, deploy) should be made available in the folder `02_model_train_deploy`. There is no child folder because no need to work on a POC. The models to deploy have already been picked. 

The folder contains a child, `Docker`, with the Dockerfile if needed. 

## Model prediction

Once the model is trained, a notebook can be created in the folder `02_model_prediction` to summarize how to make a prediction on unseen data. 



# S3 Architecture

The S3 architecture for the algorithm is as follow:

```
├── ALGORITHM
│   ├── PYTHON_SCRIPTS
│   └── YYYYMMDD
│       ├── ALGO_NAME
│       │   ├── LOGS
│       │   └── MODEL
│       ├── DATA
│       │   ├── EVALUATION
│       │   │   ├── RAW
│       │   │   └── TRANSFORM
│       │   ├── PREDICT
│       │   │   ├── RAW
│       │   │   └── TRANSFORM
│       │   └── TRAIN
│       │       ├── RAW
│       │       └── TRANSFORM
│       └── EVALUATION
```

where `YYYYMMDD` is the date when the model has been trained or retrained. Within this folder, there are two Childs, `ALGO_NAME` and `DATA`. The folder `ALGO_NAME` should be renamed according to the algorithm used (ie `XGBOOST`, `RNN` , etc). 

- `YYYYMMDD`
  - `DATA`
    - `TRAIN` -> contains the raw data to be trained on
      - `RAW`: Training raw data before preprocessing
      - `TRANSFORM`: Training data after preprocessing
      - Sagemaker referenced functions: [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html?highlight=SKLearnProcessor#sagemaker.sklearn.processing.SKLearnProcessor) or [ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html?highlight=ScriptProcessor#sagemaker.processing.ScriptProcessor) for preprocessing and [SKLearn](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html?highlight=SKLearn#sagemaker.sklearn.estimator.SKLearn) for training
    - `PREDICT`: -> contains the raw data to be predicted
      - `RAW`: Prediction raw data before preprocessing
      - `TRANSFORM`: Prediction data after preprocessing
      - Sagemaker referenced function: [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html?highlight=SKLearnProcessor#sagemaker.sklearn.processing.SKLearnProcessor) or [ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html?highlight=ScriptProcessor#sagemaker.processing.ScriptProcessor) for prediction
  - `ALGO_NAME` : Name of the algorithm used to train and predict the data
    - `LOGS`: Logs generated by Sagemaker during the training
    - `MODEL`: `tar` file with the model's object
  - `EVALUATION`: -> Contains the model evaluation performances
- `PYTHON_SCRIPTS`: Contains the preprocessing, training and evaluating scripts